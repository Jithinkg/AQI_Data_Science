{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c1f51356a6e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/Real-Data/Real_Combine.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'read_csv' is not defined"
     ]
    }
   ],
   "source": [
    "df=read_csv.read('Data/Real-Data/Real_Combine.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c1f51356a6e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/Real-Data/Real_Combine.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'read_csv' is not defined"
     ]
    }
   ],
   "source": [
    "df=read_csv.read('Data/Real-Data/Real_Combine.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Data/Real-Data/Real_Combine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "      <th>PM 2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         T     TM     Tm    SLP      H     VV      V     VM  PM 2.5\n",
       "0    False  False  False  False  False  False  False  False   False\n",
       "1    False  False  False  False  False  False  False  False   False\n",
       "2    False  False  False  False  False  False  False  False   False\n",
       "3    False  False  False  False  False  False  False  False   False\n",
       "4    False  False  False  False  False  False  False  False   False\n",
       "5    False  False  False  False  False  False  False  False   False\n",
       "6    False  False  False  False  False  False  False  False   False\n",
       "7    False  False  False  False  False  False  False  False   False\n",
       "8    False  False  False  False  False  False  False  False   False\n",
       "9    False  False  False  False  False  False  False  False   False\n",
       "10   False  False  False  False  False  False  False  False   False\n",
       "11   False  False  False  False  False  False  False  False   False\n",
       "12   False  False  False  False  False  False  False  False   False\n",
       "13   False  False  False  False  False  False  False  False   False\n",
       "14   False  False  False  False  False  False  False  False   False\n",
       "15   False  False  False  False  False  False  False  False   False\n",
       "16   False  False  False  False  False  False  False  False   False\n",
       "17   False  False  False  False  False  False  False  False   False\n",
       "18   False  False  False  False  False  False  False  False   False\n",
       "19   False  False  False  False  False  False  False  False   False\n",
       "20   False  False  False  False  False  False  False  False   False\n",
       "21   False  False  False  False  False  False  False  False   False\n",
       "22   False  False  False  False  False  False  False  False   False\n",
       "23   False  False  False  False  False  False  False  False   False\n",
       "24   False  False  False  False  False  False  False  False   False\n",
       "25   False  False  False  False  False  False  False  False   False\n",
       "26   False  False  False  False  False  False  False  False   False\n",
       "27   False  False  False  False  False  False  False  False   False\n",
       "28   False  False  False  False  False  False  False  False   False\n",
       "29   False  False  False  False  False  False  False  False   False\n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...     ...\n",
       "686  False  False  False  False  False  False  False  False   False\n",
       "687  False  False  False  False  False  False  False  False   False\n",
       "688  False  False  False  False  False  False  False  False   False\n",
       "689  False  False  False  False  False  False  False  False   False\n",
       "690  False  False  False  False  False  False  False  False   False\n",
       "691  False  False  False  False  False  False  False  False   False\n",
       "692  False  False  False  False  False  False  False  False   False\n",
       "693  False  False  False  False  False  False  False  False   False\n",
       "694  False  False  False  False  False  False  False  False   False\n",
       "695  False  False  False  False  False  False  False  False   False\n",
       "696  False  False  False  False  False  False  False  False   False\n",
       "697  False  False  False  False  False  False  False  False   False\n",
       "698  False  False  False  False  False  False  False  False   False\n",
       "699  False  False  False  False  False  False  False  False   False\n",
       "700  False  False  False  False  False  False  False  False   False\n",
       "701  False  False  False  False  False  False  False  False   False\n",
       "702  False  False  False  False  False  False  False  False   False\n",
       "703  False  False  False  False  False  False  False  False   False\n",
       "704  False  False  False  False  False  False  False  False   False\n",
       "705  False  False  False  False  False  False  False  False   False\n",
       "706  False  False  False  False  False  False  False  False   False\n",
       "707  False  False  False  False  False  False  False  False   False\n",
       "708  False  False  False  False  False  False  False  False   False\n",
       "709  False  False  False  False  False  False  False  False   False\n",
       "710  False  False  False  False  False  False  False  False   False\n",
       "711  False  False  False  False  False  False  False  False   False\n",
       "712  False  False  False  False  False  False  False  False   False\n",
       "713  False  False  False  False  False  False  False  False   False\n",
       "714  False  False  False  False  False  False  False  False   False\n",
       "715  False  False  False  False  False  False  False  False   False\n",
       "\n",
       "[716 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28b3334fcf8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=True,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-32ff1513511f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "X\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      284.795833\n",
       "1      219.720833\n",
       "2      182.187500\n",
       "3      154.037500\n",
       "4      223.208333\n",
       "5      200.645833\n",
       "6      285.225000\n",
       "7      236.825000\n",
       "8      276.908333\n",
       "9      108.000000\n",
       "10     107.625000\n",
       "11     125.891667\n",
       "12     181.012500\n",
       "13     152.554167\n",
       "14     152.320833\n",
       "15     251.375000\n",
       "16     251.829167\n",
       "17     319.737500\n",
       "18     166.300000\n",
       "19      78.254167\n",
       "20      54.958333\n",
       "21     211.125000\n",
       "22     192.291667\n",
       "23     152.000000\n",
       "24       0.000000\n",
       "25       0.000000\n",
       "26       0.000000\n",
       "27     119.333333\n",
       "28      67.125000\n",
       "29      46.708333\n",
       "          ...    \n",
       "686    217.375000\n",
       "687    309.375000\n",
       "688    166.916667\n",
       "689    278.000000\n",
       "690    192.333333\n",
       "691    235.333333\n",
       "692    221.541667\n",
       "693    210.541667\n",
       "694    251.208333\n",
       "695    194.708333\n",
       "696    250.875000\n",
       "697    274.875000\n",
       "698    160.000000\n",
       "699    217.916667\n",
       "700    184.208333\n",
       "701    176.375000\n",
       "702    185.958333\n",
       "703    195.375000\n",
       "704    365.291667\n",
       "705    312.208333\n",
       "706    237.625000\n",
       "707    202.875000\n",
       "708    260.166667\n",
       "709    403.958333\n",
       "710    284.166667\n",
       "711    288.416667\n",
       "712    256.833333\n",
       "713    169.000000\n",
       "714    186.041667\n",
       "715    185.583333\n",
       "Name: PM 2.5, Length: 716, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "5      False\n",
       "6      False\n",
       "7      False\n",
       "8      False\n",
       "9      False\n",
       "10     False\n",
       "11     False\n",
       "12     False\n",
       "13     False\n",
       "14     False\n",
       "15     False\n",
       "16     False\n",
       "17     False\n",
       "18     False\n",
       "19     False\n",
       "20     False\n",
       "21     False\n",
       "22     False\n",
       "23     False\n",
       "24     False\n",
       "25     False\n",
       "26     False\n",
       "27     False\n",
       "28     False\n",
       "29     False\n",
       "       ...  \n",
       "686    False\n",
       "687    False\n",
       "688    False\n",
       "689    False\n",
       "690    False\n",
       "691    False\n",
       "692    False\n",
       "693    False\n",
       "694    False\n",
       "695    False\n",
       "696    False\n",
       "697    False\n",
       "698    False\n",
       "699    False\n",
       "700    False\n",
       "701    False\n",
       "702    False\n",
       "703    False\n",
       "704    False\n",
       "705    False\n",
       "706    False\n",
       "707    False\n",
       "708    False\n",
       "709    False\n",
       "710    False\n",
       "711    False\n",
       "712    False\n",
       "713    False\n",
       "714    False\n",
       "715    False\n",
       "Name: PM 2.5, Length: 716, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "      <th>PM 2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965232</td>\n",
       "      <td>0.956362</td>\n",
       "      <td>-0.882812</td>\n",
       "      <td>-0.515609</td>\n",
       "      <td>0.612932</td>\n",
       "      <td>0.328821</td>\n",
       "      <td>0.294462</td>\n",
       "      <td>-0.624378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TM</th>\n",
       "      <td>0.965232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890668</td>\n",
       "      <td>-0.826499</td>\n",
       "      <td>-0.600200</td>\n",
       "      <td>0.586549</td>\n",
       "      <td>0.323313</td>\n",
       "      <td>0.307858</td>\n",
       "      <td>-0.558963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tm</th>\n",
       "      <td>0.956362</td>\n",
       "      <td>0.890668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.907536</td>\n",
       "      <td>-0.304249</td>\n",
       "      <td>0.548498</td>\n",
       "      <td>0.314538</td>\n",
       "      <td>0.265257</td>\n",
       "      <td>-0.661210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLP</th>\n",
       "      <td>-0.882812</td>\n",
       "      <td>-0.826499</td>\n",
       "      <td>-0.907536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266097</td>\n",
       "      <td>-0.483020</td>\n",
       "      <td>-0.347358</td>\n",
       "      <td>-0.305685</td>\n",
       "      <td>0.595187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>-0.515609</td>\n",
       "      <td>-0.600200</td>\n",
       "      <td>-0.304249</td>\n",
       "      <td>0.266097</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.464855</td>\n",
       "      <td>-0.395672</td>\n",
       "      <td>-0.368083</td>\n",
       "      <td>0.156819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VV</th>\n",
       "      <td>0.612932</td>\n",
       "      <td>0.586549</td>\n",
       "      <td>0.548498</td>\n",
       "      <td>-0.483020</td>\n",
       "      <td>-0.464855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400107</td>\n",
       "      <td>0.344158</td>\n",
       "      <td>-0.521898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>0.328821</td>\n",
       "      <td>0.323313</td>\n",
       "      <td>0.314538</td>\n",
       "      <td>-0.347358</td>\n",
       "      <td>-0.395672</td>\n",
       "      <td>0.400107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759179</td>\n",
       "      <td>-0.238194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VM</th>\n",
       "      <td>0.294462</td>\n",
       "      <td>0.307858</td>\n",
       "      <td>0.265257</td>\n",
       "      <td>-0.305685</td>\n",
       "      <td>-0.368083</td>\n",
       "      <td>0.344158</td>\n",
       "      <td>0.759179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PM 2.5</th>\n",
       "      <td>-0.624378</td>\n",
       "      <td>-0.558963</td>\n",
       "      <td>-0.661210</td>\n",
       "      <td>0.595187</td>\n",
       "      <td>0.156819</td>\n",
       "      <td>-0.521898</td>\n",
       "      <td>-0.238194</td>\n",
       "      <td>-0.199662</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               T        TM        Tm       SLP         H        VV         V  \\\n",
       "T       1.000000  0.965232  0.956362 -0.882812 -0.515609  0.612932  0.328821   \n",
       "TM      0.965232  1.000000  0.890668 -0.826499 -0.600200  0.586549  0.323313   \n",
       "Tm      0.956362  0.890668  1.000000 -0.907536 -0.304249  0.548498  0.314538   \n",
       "SLP    -0.882812 -0.826499 -0.907536  1.000000  0.266097 -0.483020 -0.347358   \n",
       "H      -0.515609 -0.600200 -0.304249  0.266097  1.000000 -0.464855 -0.395672   \n",
       "VV      0.612932  0.586549  0.548498 -0.483020 -0.464855  1.000000  0.400107   \n",
       "V       0.328821  0.323313  0.314538 -0.347358 -0.395672  0.400107  1.000000   \n",
       "VM      0.294462  0.307858  0.265257 -0.305685 -0.368083  0.344158  0.759179   \n",
       "PM 2.5 -0.624378 -0.558963 -0.661210  0.595187  0.156819 -0.521898 -0.238194   \n",
       "\n",
       "              VM    PM 2.5  \n",
       "T       0.294462 -0.624378  \n",
       "TM      0.307858 -0.558963  \n",
       "Tm      0.265257 -0.661210  \n",
       "SLP    -0.305685  0.595187  \n",
       "H      -0.368083  0.156819  \n",
       "VV      0.344158 -0.521898  \n",
       "V       0.759179 -0.238194  \n",
       "VM      1.000000 -0.199662  \n",
       "PM 2.5 -0.199662  1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-578d37c7dc05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mdistplot\u001b[1;34m(a, bins, hist, kde, rug, fit, hist_kws, kde_kws, rug_kws, fit_kws, color, vertical, norm_hist, axlabel, label, ax)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbins\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_freedman_diaconis_bins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[0mhist_kws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"alpha\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"2.2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36m_freedman_diaconis_bins\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-dd12567c1f63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"coeff of detr R^2  :{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 458\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[1;32m--> 759\u001b[1;33m                         dtype=None)\n\u001b[0m\u001b[0;32m    760\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train,y_train)\n",
    "print(\"coeff of detr R^2  :{}\".format(regressor.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "      <th>PM 2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1017.4</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>284.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1017.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>219.720833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.7</td>\n",
       "      <td>26.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1015.3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>182.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1018.4</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>18.3</td>\n",
       "      <td>154.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.7</td>\n",
       "      <td>21.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1017.1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>22.2</td>\n",
       "      <td>223.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.8</td>\n",
       "      <td>22.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>18.3</td>\n",
       "      <td>200.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.4</td>\n",
       "      <td>25.4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>285.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.1</td>\n",
       "      <td>26.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1013.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>236.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.3</td>\n",
       "      <td>23.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>1011.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>276.908333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1015.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>22.2</td>\n",
       "      <td>107.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.3</td>\n",
       "      <td>26.9</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1015.6</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>125.891667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17.2</td>\n",
       "      <td>24.2</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>181.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17.7</td>\n",
       "      <td>26.5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1015.3</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.8</td>\n",
       "      <td>152.554167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.4</td>\n",
       "      <td>28.4</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1014.7</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>152.320833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18.2</td>\n",
       "      <td>26.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1016.3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>24.4</td>\n",
       "      <td>33.5</td>\n",
       "      <td>251.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1016.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>16.7</td>\n",
       "      <td>29.4</td>\n",
       "      <td>251.829167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.7</td>\n",
       "      <td>27.8</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1016.2</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.9</td>\n",
       "      <td>319.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22.6</td>\n",
       "      <td>30.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1015.4</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>20.6</td>\n",
       "      <td>166.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22.5</td>\n",
       "      <td>31.8</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1014.6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>14.8</td>\n",
       "      <td>78.254167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>18.3</td>\n",
       "      <td>54.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23.8</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1010.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>211.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>1013.1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>11.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>192.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1016.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.6</td>\n",
       "      <td>31.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>1008.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.1</td>\n",
       "      <td>34.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.1</td>\n",
       "      <td>34.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>11.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23.6</td>\n",
       "      <td>34.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1010.4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>15.9</td>\n",
       "      <td>22.2</td>\n",
       "      <td>119.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23.2</td>\n",
       "      <td>29.6</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1008.6</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>13.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>67.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>23.8</td>\n",
       "      <td>30.9</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>46.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>23.4</td>\n",
       "      <td>31.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>217.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>22.6</td>\n",
       "      <td>30.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1015.4</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>309.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>23.9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1015.6</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>166.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>23.2</td>\n",
       "      <td>30.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>18.3</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>22.5</td>\n",
       "      <td>29.5</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1013.3</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>192.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>21.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1014.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>16.5</td>\n",
       "      <td>235.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>22.2</td>\n",
       "      <td>30.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1015.6</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>221.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>20.8</td>\n",
       "      <td>29.3</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>210.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>20.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>251.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>20.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1013.9</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>194.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1013.2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>14.8</td>\n",
       "      <td>250.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>21.4</td>\n",
       "      <td>30.6</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1011.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>18.3</td>\n",
       "      <td>274.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>24.2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>13.9</td>\n",
       "      <td>22.2</td>\n",
       "      <td>160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>22.7</td>\n",
       "      <td>30.8</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>11.9</td>\n",
       "      <td>20.6</td>\n",
       "      <td>217.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>21.4</td>\n",
       "      <td>29.6</td>\n",
       "      <td>12.7</td>\n",
       "      <td>1013.7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>184.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>19.2</td>\n",
       "      <td>25.9</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>176.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>18.9</td>\n",
       "      <td>25.8</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>185.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>19.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1019.6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>195.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>17.8</td>\n",
       "      <td>24.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>365.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>15.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>312.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>18.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1013.7</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>237.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>19.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1015.1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>202.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>18.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1017.1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>260.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>17.2</td>\n",
       "      <td>24.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1017.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>403.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>16.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1016.9</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>284.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>18.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1015.4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>288.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>17.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>22.2</td>\n",
       "      <td>256.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>13.9</td>\n",
       "      <td>24.5</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>16.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1016.9</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>16.5</td>\n",
       "      <td>186.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>16.3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1017.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>18.3</td>\n",
       "      <td>185.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>715 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        T    TM    Tm     SLP     H   VV     V    VM      PM 2.5\n",
       "0    15.0  24.0   7.6  1017.4  81.0  0.6   2.2   7.6  284.795833\n",
       "1    16.3  24.0  12.0  1017.2  80.0  0.8   1.3   9.4  219.720833\n",
       "2    18.7  26.3   9.5  1015.3  64.0  1.6   1.7   7.6  182.187500\n",
       "3    14.6  21.6   9.4  1018.4  72.0  2.7   9.4  18.3  154.037500\n",
       "4    14.7  21.7   8.4  1017.1  71.0  1.8  10.9  22.2  223.208333\n",
       "5    14.8  22.6   8.5  1016.8  67.0  2.1   9.3  18.3  200.645833\n",
       "6    17.4  25.4  10.3  1015.8  63.0  1.9   6.7  14.8  285.225000\n",
       "7    18.1  26.7  10.2  1013.8  61.0  2.6   5.0  11.1  236.825000\n",
       "8    18.3  23.2  12.7  1011.2  75.0  1.9  10.0  22.2  276.908333\n",
       "9    16.4  22.0  11.2  1015.5  81.0  1.6   5.9  18.3  108.000000\n",
       "10   16.9  23.5  10.1  1016.8  80.0  1.3   5.2  22.2  107.625000\n",
       "11   19.3  26.9  12.1  1015.6  74.0  1.6   5.9  11.1  125.891667\n",
       "12   17.2  24.2  10.8  1018.3  74.0  2.6   4.6  14.8  181.012500\n",
       "13   17.7  26.5   9.8  1015.3  73.0  1.4   4.8  14.8  152.554167\n",
       "14   20.4  28.4  15.2  1014.7  62.0  2.4   5.0  14.8  152.320833\n",
       "15   18.2  26.1  12.2  1016.3  54.0  1.9  24.4  33.5  251.375000\n",
       "16   19.0  26.8  11.7  1016.3  58.0  2.6  16.7  29.4  251.829167\n",
       "17   18.7  27.8  13.3  1016.2  69.0  2.4   7.4  25.9  319.737500\n",
       "18   22.6  30.6  15.7  1015.4  62.0  2.6   8.1  20.6  166.300000\n",
       "19   22.5  31.8  13.7  1014.6  57.0  2.3   5.9  14.8   78.254167\n",
       "20   24.0  33.8  13.6  1009.7  53.0  1.9   4.6  18.3   54.958333\n",
       "21   23.8  33.0  14.9  1010.4  64.0  1.9   3.9  11.1  211.125000\n",
       "22   22.6  33.0  18.1  1013.1  67.0  2.1  11.3  22.2  192.291667\n",
       "23   23.0  30.0  14.4  1016.1  55.0  2.7   6.7  14.8  152.000000\n",
       "24   24.6  31.7  17.9  1008.5  68.0  2.3  14.1  27.8    0.000000\n",
       "25   27.1  34.8  17.7  1009.7  52.0  1.6   6.1  11.1    0.000000\n",
       "26   26.1  34.8  17.9  1008.8  54.0  2.6  11.9  18.3    0.000000\n",
       "27   23.6  34.3  17.7  1010.4  51.0  2.6  15.9  22.2  119.333333\n",
       "28   23.2  29.6  16.7  1008.6  54.0  1.9  13.1  22.2   67.125000\n",
       "29   23.8  30.9  16.7  1009.0  52.0  1.6   6.5  13.0   46.708333\n",
       "..    ...   ...   ...     ...   ...  ...   ...   ...         ...\n",
       "686  23.4  31.1  14.2  1016.0  60.0  1.1   3.0   7.6  217.375000\n",
       "687  22.6  30.6  15.8  1015.4  69.0  0.5   1.1   5.4  309.375000\n",
       "688  23.9  32.0  14.5  1015.6  63.0  1.0   2.0   5.4  166.916667\n",
       "689  23.2  30.2  14.0  1012.6  55.0  1.1   7.4  18.3  278.000000\n",
       "690  22.5  29.5  15.6  1013.3  56.0  1.1  11.7  22.2  192.333333\n",
       "691  21.7  30.0  12.2  1014.5  52.0  1.1   6.3  16.5  235.333333\n",
       "692  22.2  30.2  13.6  1015.6  63.0  1.6   1.5   3.5  221.541667\n",
       "693  20.8  29.3  12.1  1016.7  58.0  1.8   3.5   9.4  210.541667\n",
       "694  20.7  28.8  10.6  1017.8  56.0  1.8   6.1  16.5  251.208333\n",
       "695  20.8  29.0  10.5  1013.9  61.0  1.8   2.6   7.6  194.708333\n",
       "696  22.0  31.0  10.7  1013.2  56.0  1.8   2.4  14.8  250.875000\n",
       "697  21.4  30.6  10.8  1011.9  54.0  2.6   7.8  18.3  274.875000\n",
       "698  24.2  31.0  16.5  1013.0  36.0  2.9  13.9  22.2  160.000000\n",
       "699  22.7  30.8  13.6  1012.0  38.0  3.4  11.9  20.6  217.916667\n",
       "700  21.4  29.6  12.7  1013.7  40.0  2.6   8.0  20.6  184.208333\n",
       "701  19.2  25.9  11.9  1017.0  84.0  0.8   2.6   9.4  176.375000\n",
       "702  18.9  25.8  11.5  1017.9  77.0  0.6   5.0  13.0  185.958333\n",
       "703  19.3  27.0  11.7  1019.6  57.0  1.8   5.2  11.1  195.375000\n",
       "704  17.8  24.8  11.2  1017.0  74.0  0.6   0.7   7.6  365.291667\n",
       "705  15.8  24.3   8.7  1015.8  77.0  0.8   1.7   7.6  312.208333\n",
       "706  18.2  27.0   7.7  1013.7  72.0  0.6   1.1   7.6  237.625000\n",
       "707  19.0  27.1  10.5  1015.1  61.0  1.6   3.3   9.4  202.875000\n",
       "708  18.0  26.6  10.5  1017.1  61.0  1.9   8.0  14.8  260.166667\n",
       "709  17.2  24.2  10.0  1017.2  58.0  1.6   9.3  22.2  403.958333\n",
       "710  16.3  23.0   6.6  1016.9  61.0  1.0   9.4  20.6  284.166667\n",
       "711  18.1  24.0  11.2  1015.4  56.0  1.8  15.9  25.9  288.416667\n",
       "712  17.8  25.0  10.7  1015.8  54.0  2.3   9.4  22.2  256.833333\n",
       "713  13.9  24.5  11.4  1015.0  95.0  0.6   8.7  14.8  169.000000\n",
       "714  16.3  23.0   9.8  1016.9  78.0  1.1   7.4  16.5  186.041667\n",
       "715  16.3  23.4   9.0  1017.3  68.0  1.3   7.8  18.3  185.583333\n",
       "\n",
       "[715 rows x 9 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-dd12567c1f63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"coeff of detr R^2  :{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 458\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[1;32m--> 759\u001b[1;33m                         dtype=None)\n\u001b[0m\u001b[0;32m    760\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train,y_train)\n",
    "print(\"coeff of detr R^2  :{}\".format(regressor.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7f0359aeb621>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-bd78f3457439>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 458\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[1;32m--> 759\u001b[1;33m                         dtype=None)\n\u001b[0m\u001b[0;32m    760\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-8d95067771c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlin_regressor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlin_regressor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmean_mse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_mse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "lin_regressor=LinearRegression()\n",
    "mse=cross_val_score(lin_regressor,X,y,scoring='neg_mean_squared_error',cv=5)\n",
    "mean_mse=np.mean(mse)\n",
    "print(mean_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-3679c10d8a5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlin_regressor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlin_regressor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmean_mse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_mse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \"\"\"\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[1;32m---> 98\u001b[1;33m                                                  **self._kwargs)\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \"\"\"\n\u001b[0;32m    238\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 239\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "lin_regressor=LinearRegression()\n",
    "mse=cross_val_score(lin_regressor,X,y,scoring='neg_mean_squared_error',cv=5)\n",
    "mean_mse=np.mean(mse)\n",
    "print(mean_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
